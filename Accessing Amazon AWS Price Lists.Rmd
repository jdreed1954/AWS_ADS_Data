---
title: "Accessing Amazon AWS Price Lists"
author: "James D. Reed"
date: "June 6, 2018"
output:
  pdf_document: default
  html_document:
    df_print: paged
    fontsize: 12pt
header-includes: \usepackage{fancyhdr} \pagestyle{fancy} \fancyhead[CO,CE]{} \fancyfoot[CO,CE]{
  Access Amazon AWS Price Lists} \fancyfoot[LE,RO]{\thepage}
---

```{r setup, include=FALSE}
library(tidyverse)
library(RCurl)
library(XML)
library(jsonlite)

knitr::opts_chunk$set(echo = TRUE)
```

# Accessing Amazon AWS Price Lists

Amazon provides an API to access its pricing details for Amazon Web Services (AWS).  These data can be used for estimating the cost of cloud solutions and doing what-if anaysis when deciding future fluctuations in cloud infratructure.

The purpose of this paper is to illustrate how R can be used to retrieve and analyze AWS pricing data  Further, I hope to show by example how the *purrr* and functional programming methods can be used to streamline your code and minimize your need to break out the old trustworthy **for loop.**  Programming is like the fine apparel industry, what is in style now will soon be passe and to be avoided at all costs.  Back in the time of the dinasauers (1960s and 70s), when Fortran was all the rage, the **goto** statement was the Swiss-Army knife of programming.  When in doubt, put in a numeric line label (columns 1 through 5) and place a **goto** anywhere in scope to continue execution from that point.  As programmers got better, this "spaghetti code" created by the liberal use of the **goto** was seen to be a culprit.  We spoke of top down programming and the begginings of structured programming.  The Fortran language itself followed suit years later with Fortran 90 which among other things, reduced the requirements for line labels allowed the **do loop** to exist without labels.  This yielded cleaner code and better programming in general.  Alas, the art of Fortran programming has waned in the recent past, replaced with more elegant and object oriented languages like C++, C# and Java.

Indeed, in the scientific arena, it is not uncommon to see Python and R used, but even with these modern languages, there is the constant move forward, the incremental improvements in form and style of the language itself and the *best* ways to use it.



#### Recent Innovations in the R Language

The most impressive recent innovations in R, aside from the **tidyverse** (I am a big fan!) it the pipe function and the **purrr** package

### Using the Bulk API

>The AWS Price List API is actually a URL that provides up-to-date pricing information on the current AWS products and services. To access pricing information using the AWS Price List API, download the offer file:

>Offer file – A JSON or CSV file that lists the products and prices for either a single AWS service in all regions or a single AWS service in a specific region. For more information, see Downloading an Offer File.

>To find a list of all available offer files, download the offer index file:

>Offer index file – A JSON file that lists the supported AWS services, with a URL for each offer file where you can download pricing details. The file also includes metadata about the offer index file itself, URLs for service offer files, and URLs for regional offer index files. For more information, see **Downloading an Offer Index File.**

>Offer files do not include information about expiring free tier offers or Amazon EC2 Spot Instances.

>Note

>The AWS Price List API provides pricing details for your information only. If  there is a discrepancy between the offer file and a service pricing page, AWS charges the prices that are listed on the service pricing page. For more  information about AWS service pricing, see **Cloud Services Pricing.**

Offers JSON is a directory of pricing files for various price lists.  Each file can be downloaded or each region.  There *may* be price differences from region to region.  



```{r}

# Start here.  
# This is the JSON file that contains the addresses to each offer (product area).
PricingJSON <- "https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/index.json"

# The getURL function delivers the object represented by the URL (PricingJSON).  
# This object is, in fact a JSON file.
doc <- getURL(PricingJSON)

# The fromJSON function converts this JSON file into an R object (a list of lists).
root <- fromJSON(doc)

```


Root is a list of lists.  The best way to see this is to get a *summary.*

```{r}
summary(root)
```

The top three items are informational data about the JSON, the format version, a disclaimer and the publication date.

```{r}
root$formatVersion
```

```{r}
root$disclaimer
```

```{r}
root$publicationDate
```

Of course, the real core of the pricing JSON is the list of **offers**.  Accessing these is harder than one would think.

The first thing we need to do is get the offers object separate from the rest of the JSON file.  Next, we can get a list of the offerNames or offer codes.

Here is are first opportunity for us to use the *purrr* package. 

```{r}
# Isolate the offers from the rest of the R object .
offers <- root$offers

numOffer   <-  length(offers)
offerNames <-  map_chr(1:numOffer, ~ as.character(offers[[.x]]['offerCode']))

offer_tbl <-  tibble(
                  Item = seq(1:numOffer),
                  Names = offerNames
    )

knitr::kable(offer_tbl, col.names = c("Item #","Offer Names"))

```

## Regions and Codes

At the time of this writing, AWS has sixteen regions spread across the world, that most commercial customers can access.  The regions not listed here are the COV and China Regions.


```{r}
regionTbl <- tibble(
  Item  = seq(1:16),
  
  Code	= c("us-east-1",      "us-east-2",      "us-west-1",      "us-west-2", 
            "ca-central-1",   "eu-central-1",   "eu-west-1",      "eu-west-2", 
            "eu-west-3",      "ap-northeast-1", "ap-northeast-2", "ap-northeast-3", 
            "ap-southeast-1", "ap-southeast-2", "ap-south-1",     "sa-east-1"),
  
  Name	= c("US East (N. Virginia)", "US East (Ohio)",  "US West (N. California)", 
            "US West (Oregon)",      "Canada (Central)","EU (Frankfurt)",        
            "EU (Ireland)",          "EU (London)",     "EU (Paris)",      
            "AP (Tokyo)",            "AP (Seoul)",      "AP (Osaka-Local)",
            "AP (Singapore)",        "AP (Sydney)",     "AP (Mumbai)", 
            "SA (São Paulo)")

)

knitr::kable(regionTbl)

```

We can use these region codes to pull price lists designated to particular region.

```{r echo=FALSE, message=FALSE, warning=FALSE}
destFile <- "pricing/priceMaster"
if (!file.exists(destFile)) {

    # This is a long running part of the code because we are reading in each of the pricing tables from the internet.
    # So, let 's time it see what to expect.
    ptm <- proc.time()
    
    # Build tibble for Offer Names URLs (both JSON and CSV) and the pricing tables.  All using map functions!
    priceMaster <- tibble(
      Item = c(1:numOffer),
      offerName = offerNames,
      pURL      = map_chr(1:numOffer, ~ as.character(offers[[.x]]['currentVersionUrl'])),
      JSON      = map_chr(1:numOffer, ~ paste("https://pricing.","us-east-1",".amazonaws.com", pURL[.x], sep = "")),
      CSV       = map_chr(JSON, ~ gsub("json$", "csv", .x)),
      priceTbl  = map(CSV, ~ read_csv(.x, skip = 5, progress = FALSE))
    )
    
    
    proc.time() - ptm
    save(list = c("priceMaster"), file = destFile)

} else {
  
  load(destFile)
}

knitr::kable(priceMaster[,c(1:3)], col.names = (c("Item #", "Offer Name", "Current Version URL")))
```

\clearpage

## Extracting a Pricelist

So, we want to extract the EC2 pricelist to do some comparisons of models we are interested in using.

The EC2 entry above has an index of 30.  One of the ways of getting a copy of the pricelist is with the following command:

$$ec2List <-  priceMaster[[30, 'priceTbl']]]      $$

Okay, so the syntax is not so obvious, but I am sure by experimenting you would come up with it like I did.

```{r}
ec2List <- priceMaster[[30, 'priceTbl']]
```


This is a very large table.Over 430,000 rows and 77 columns.  Let's have a look at the column names and see if we can make sense of how this table is made.  The goal is to find the records we care about and filter/select out the rest.

```{r}
names(ec2List)
```

With a bit of exploring of the variables and their values, one can figure out a strategy for cutting this table down to a maneageble set of data.

At this point I am just trying to compare the prices of EC2 models in the US and only "OnDemand," not reserved or dedicated.

```{r}
 MyEC2List <- filter(ec2List, TermType == "OnDemand" & grepl("Oregon", Location)) %>%
      select(1:40) 
```


```{r}

# Rename some of the columns.
names(MyEC2List)[names(MyEC2List) == "Instance Type"] <- "Name"
names(MyEC2List)[names(MyEC2List) == "Network Performance"] <- "Network.Performance"
names(MyEC2List)[names(MyEC2List) == "Operating System"] <- "OS"
names(MyEC2List)[names(MyEC2List) == "LeaseContractLength"] <- "Lease.Len"
names(MyEC2List)[names(MyEC2List) == "Clock Speed"] <- "ClockSpeed"


EC2 <- MyEC2List %>% select(c(Name, vCPU, Memory, Storage, Network.Performance,  OS, Tenancy, PricePerUnit, Unit, TermType,
                             Lease.Len )) %>%
        filter(OS == "Linux", Tenancy == "Shared") %>% arrange(Name)

knitr::kable(EC2)
```

