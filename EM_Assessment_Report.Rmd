---
title: "Educational Measures Systems Performance Report"
author: "Prestige Services, LLC"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  word_document:
    df_print: tibble
    fig_caption: yes
    fig_height: 5
    fig_width: 6
    highlight: espresso
    keep_md: yes
    reference_docx: word-style-reference-V1.docx
  html_document:
    df_print: paged
  pdf_document:
        includes:
          in_header: header.tex
#   fontsize: 12pt
# header-includes: \usepackage{fancyhdr} \pagestyle{fancy} \fancyhead[CO,CE]{} \fancyfoot[CO,CE]{
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(flextable)
library(openxlsx)
library(kableExtra)

DataRoot <- "../EM-Data/agentExports"
Customer <-  "EM"
HdrBg <- "lightsteelblue1"

source("awsADS_functions.R")

knitr::opts_chunk$set(echo = FALSE)
```

# Systems Assessment for Educational Measures

## Executive Summary

Educational Measures (EM) contracted Prestige Services LLC (PS) to assess their hosted workloads to evaluate the likelyhood of migrating to a public cloud.  PS undertook this assessment by taking the following actions:

 * Interviews of stakeholders
 * Initiation of Amazon Web Services Application Discovery Service (AWS/ADS) agents on twenty-one EM virtual machines.
 * Collect at least ten business days of configuration and performance data (CPU, Memory, Network, and Disk).
 * Summarize and evaluate characteristics of each virtual machine to determine the best recommendation as it pertains to cloud migration.
 
Most VMs are operating well within their capacities with the exception of **anand**, which is operating at 97 percent (95th percentile) CPU.  This virtual machine is responsible for continuous integration (CI) and source code management (SCM).  If this VM continues its role in the cloud, its capacity should be increased and utilization monitored carefully.

The next phase in the journey to cloud will involve the planning of the actual migration of EM's current workloads.  From a high levelm there are six strategies to migrate.

1. **Rehost ("lift and shift")**

In a large legacy migration scenario where the organization is looking to quickly implement its migration and scale to meet a business case, we find that the majority of applications are rehosted. Most rehosting can be automated with tools such as AWS SMS although you may prefer to do this manually as you learn how to apply your legacy systems to the cloud.

You may also find that applications are easier to re-architect once they are already running in the cloud. This happens partly because your organization will have developed better skills to do so and partly because the hard part - migrating the application, data, and traffic - has already been accomplished.

2. **Replatform ("lift, tinker and shift")**

This entails making a few cloud optimizations in order to achieve some tangible benefit without changing the core architecture of the application. For example, you may be looking to reduce the amount of time you spend managing database instances by migrating to a managed relational database service such as Amazon Relational Database Service (RDS), or migrating your application to a fully managed platform like AWS Elastic Beanstalk.

3. **Repurchase ("drop and shop")**

This is a decision to move to a different product and likely means your organization is willing to change the existing licensing model you have been using. For workloads that can easily be upgraded to newer versions, this strategy might allow a feature set upgrade and smoother implementation.

4. **Refactor/ Re-architect**

Typically, this is driven by a strong business need to add features, scale, or performance that would otherwise be difficult to achieve in the applicationâ€™s existing environment. If your organization is looking to boost agility or improve business continuity by moving to a service-oriented architecture (SOA) this strategy may be worth pursuing - even though it is often the most expensive solution.

5. **Retire**

Identifying IT assets that are no longer useful and can be turned off will help boost your business case and direct your attention towards maintaining the resources that are widely used.

6. **Retain**

You may want to retain portions of your IT portfolio because there are some applications that you are not ready to migrate and feel more comfortable keeping them on-premises, or you are not ready to prioritize an application that was recently upgraded and then make changes to it again.

A combination of two or more of these strategies may be applied.  

### Virtual Machine Summary - IP Address and Recorded Performance Timespan
 
The following table documents each virtual machines coverage timespan. Note that **anand**, **caruana** and **lasker** are the only systems with less that fifteen days coverage.
 
 
```{r HostSummary, results = 'asis', fig.cap = "Performance Days by Hostname"}
hs <- getHostSummary(DataRoot)
hs$Last <- substring(ymd_hms(hs$Last),1,10)
hs$First <- substring(ymd_hms(hs$First),1,10)
hs$OS.Name <- substring(hs$OS.Name, 1,15)

 ft <- flextable(hs, col_keys = c("Number", "Host", "IP", "First", "Last", "Perf.Days")) %>%
       theme_booktabs() %>%
       bg(bg = HdrBg, part = "header") %>%
       bg(i = ~ Perf.Days < 15.0, bg = "#EFEF99" ) %>%
       add_footer(Number = "Highlighted rows: Less than 15 days or performance data.") %>%
       merge_at(j = 1:6, part = "footer")
     

autofit(ft, add_w = 0, add_h = 0)
```

### Virtual Machine Summary - OS Name and Version
 
 
```{r HostSummary2, results = 'asis', fig.cap = "Performance Days by Hostname"}
hs$OS.Name <- substring(hs$OS.Name,1,15)

ft <- flextable(hs, col_keys = c("Host", "OS.Name", "OS.Version")) %>%
      theme_booktabs() %>%
      bg(bg = HdrBg, part = "header") %>%
      bg(i = ~ grepl("Ubuntu", OS.Name), bg = "#EFEF99" ) %>%
      add_footer(Host = "*Highlighted rows: Ubuntu Linux 12.4.0.0. Extended Security Maintenance.") %>%
      merge_at(j = 1:3, part = "footer")

autofit(ft)
```

## System Performance Summaries

### CPU Utilization

```{r CPU, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

compInventory <- getCompInventory(DataRoot)
df <- compInventory %>% arrange(hostName, timestamp)


cpu_sizing <- getCPUs(df) %>% arrange(Host)

ft <- regulartable(cpu_sizing) %>%
     theme_booktabs() %>%
     bg(bg = HdrBg, part = "header") %>%
     bg(i = ~ CPU != CPUs.Rec, bg = "#EFEF99" ) %>% 
     add_footer(Host = "*Highlighted rows: recomended CPU count is different from current.") %>%
     merge_at( j = 1:7, part = "footer")

autofit(ft)
```

### Memory Utilization

```{r MemTab}
mem_sizing <- getMEMs(df)
mem_sizing <-  mem_sizing %>%
  mutate(RAM.Rec = ifelse(RAM.util < 48.0, RAM.GB/2, RAM.GB)) %>% select(-c(5,6)) %>% arrange(Host)
  
fmu <- flextable(mem_sizing,
  col_keys = c("Host","Min","Max","Mean", "RAM.MB", "RAM.GB", "RAM.util", "RAM.Rec")) %>%
  theme_booktabs() %>%
  bg(bg = HdrBg, part = "header") %>%
  bg(i = ~ RAM.GB != RAM.Rec, bg = "#EFEF99" ) %>%
  add_footer(Host = "*Highlighted rows: recomended RAM is different from current.") %>%
  merge_at(j = 1:7, part = "footer")


autofit(fmu)

```

### Network Read/Write

#### Network Bytes Read Per Second


```{r NetTab}

net_stats <- getNetStats(df)
 
ftr <- flextable(net_stats$NetworkRead,
     col_keys = c("Host","Min","Max","Mean", "Std", "Med", "P95" )) %>%
     theme_booktabs() %>%
     bg(bg = HdrBg, part = "header") %>%
     bg(i = ~ Max == max(Max), bg = "#EFEF99" ) %>%
     add_footer(Host = "*Highlighted row: Network Maximum Bytes Read/s") %>%
     merge_at(j = 1:7, part = "footer")

autofit(ftr)
```

#### Network Bytes Written Per Second

```{r NetTab2}
ftw <- flextable(net_stats$NetworkWrite,
   col_keys = c("Host","Min","Max","Mean", "Std", "Med", "P95" )) %>%
   theme_booktabs() %>%
   bg(bg = HdrBg, part = "header") %>%
   bg(i = ~ Max == max(Max), bg = "#EFEF99" ) %>%
   add_footer(Host = "*Highlighted row: Network Maximum Bytes Written/s") %>%
   merge_at(j = 1:7, part = "footer")

autofit(ftw)
```

### Disk Read/Write Bytes Per Second

#### Disk Read Bytes Per Second

```{r DiskTab1}
rw_stats <- getDiskRWStats(df)


ftr <- flextable(rw_stats$DiskRead,
      col_keys = c("Host","Min","Max","Mean", "Std", "Med", "P95" )) %>%
      theme_booktabs() %>%
      bg(bg = HdrBg, part = "header") %>%
      bg(i = ~ Max == max(Max), bg = "#EFEF99" )  %>%
      add_footer(Host = "*Highlighted row: Network Maximum Bytes Written/s.") %>%
      merge_at(j = 1:7, part = "footer")

autofit(ftr)
```

#### Disk Write Bytes Per Second

```{r DskTab2}
ftw <- flextable(rw_stats$DiskWrite,
      col_keys = c("Host","Min","Max","Mean", "Std", "Med", "P95" )) %>%
      theme_booktabs() %>%
      bg(bg = HdrBg, part = "header") %>%
      bg(i = ~ Max == max(Max), bg = "#EFEF99" )  %>%
      add_footer(Host = "*Highlighted row: Network Maximum Bytes Read/s.") %>%
      merge_at(j = 1:7, part = "footer")

autofit(ftw)

```

### Disk Read/Write Operations Per Second

#### Disk Read Operations Per Second

```{r DskOps1}
rw_stats <- getDiskOpsStats(df)


ftr <- flextable(rw_stats$DiskReadOps,
      col_keys = c("Host","Min","Max","Mean", "Std", "Med", "P95" )) %>%
      theme_booktabs() %>%
      bg(bg = HdrBg, part = "header") %>%
      bg(i = ~ Max == max(Max), bg = "#EFEF99" )  %>%
      add_footer(Host = "*Highlighted row: Maximum Disk Read Operations/s.") %>%
      merge_at(j = 1:7, part = "footer")


autofit(ftr)

```


#### Disk Write Operations Per Second


```{r DskOps2}
ftw <- flextable(rw_stats$DiskWriteOps,
      col_keys = c("Host","Min","Max","Mean", "Std", "Med", "P95" )) %>%
      theme_booktabs() %>%
      bg(bg = HdrBg, part = "header") %>%
      bg(i = ~ Max == max(Max), bg = "#EFEF99" ) %>%
      add_footer(Host = "*Highlighted row: Maximum Disk Write Operations/s.") %>%
      merge_at(j = 1:7, part = "footer")


autofit(ftw)
```


### VM Storage Capacity Details and Role

```{r VMDet}
hostRoles <- tibble(
  Host = c(
    "alekhine",        "anand",        "caruana",             "PostgresCanary", "analytics",
    "postgres-pr-001", "centralmysql", "CentralMySQLReplica", "Euwe",           "golive",
    "hou7",            "kosteniuk7",   "kramnik7",            "lasker",         "menchik7", 
    "polgar7",         "smyslov",      "VirtualMySQL",        "Fischer",        "kasparov", 
    "Tal"),
  Role = c(
    "DNS server" ,     "Source Control and CI server", "Hosting server for wordpress, SFTP and other web sites",
    "Yellow Fin Analytics support servers", "Yellowfin Analytics applications server", 
    "Yellowfin Analytics database server",  "Database server to support Euwe, Central.arraylearn.com",
    "Replica of centralmysql to support Analytics reports", 
    "Application server to support CentralMySQL,Central.arraylearn.com", 
    "Autonomous Array server", "Autonomous Array server",  "Autonomous Array server",  
    "Autonomous Array server", "Autonomous Array server", "Autonomous Array server", 
    "Autonomous Array server", 
    "Distributed Applications Array server supports VirtualMySQL", 
    "Distributed Database Array server supports Smyslov",
    "Edtrak QA server", "EdTrak related hosting www servers", "EdTrack Production Server")
)

StorageFile <- "EM_All_Storage.xlsx"
storageTbl <- read.xlsx(StorageFile)

storagePer <-  storageTbl %>% 
  arrange(Host, FileSystem) %>% 
  distinct(Host, FileSystem, Size.MB, .keep_all = TRUE) %>%
  group_by(Host) %>%
  summarize( TotalCap.G = sum(Size.MB)/1024, TotalFree.G = sum(FreeSpace.MB)/1024) %>%
  mutate(PctUsed = (TotalCap.G- TotalFree.G)/TotalCap.G * 100)

storagePer <- left_join(storagePer, hostRoles, by = "Host")

ft <- flextable(storagePer, 
                col_keys = c("Host", "TotalCap.G", "TotalFree.G",  "PctUsed",  "Role")) %>%
  theme_booktabs() %>%
  bg(bg = HdrBg, part = "header") %>%
  bg(i = ~ PctUsed == max(PctUsed), bg = "#EFEF99" ) %>% 
  bg(i = ~ TotalCap.G == max(TotalCap.G), bg = "wheat3" ) %>%
  add_footer(Host = paste("*Highlighted row: Maximum Percent Utilization (PctUsed).", 
                          " *Highlighted row: Maximum Total Disk Capacity (TotalCap.G).", sep = "")) %>%
  merge_at(j = 1:5, part = "footer")


autofit(ft)
```
 


### CPU Utilization Histogram

```{r CPUpct, gig.height = 6.0, echo=FALSE, message=FALSE, warning=FALSE}
library(scales)
library(data.table)
ce <- tibble(
  Host = cpu_sizing$Host,
  Mean = cpu_sizing$Mean,
  P95  = cpu_sizing$P95,
  Max  = cpu_sizing$Max
)
legend_title <- "Statistic"

ce <- arrange(ce, Host)
mce <- melt(ce,id.vars = "Host")
ggplot(mce, aes(x = Host, y = value, fill = variable)) + 
  geom_bar(position = "dodge", stat = "identity") + ylab("Percent CPU Utilization") +
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) +
  theme(legend.position = "top") + labs(fill = "Statistic")

```

### Memory Utilization Histogram

```{r MemPct, fig.height = 6.0}

mem_sizing <- getMEMs(df)

me <- tibble(
  Host = mem_sizing$Host,
  Mean = mem_sizing$Mean,
  Max  = mem_sizing$Max,
  RAM  = mem_sizing$RAM.MB
)

me <- arrange(me, Host)
mme <- melt(me,id.vars = "Host")

ggplot(mme, aes(x = Host, y = value, fill = variable)) + 
  geom_bar(position = "dodge", stat = "identity") + ylab("RAM Utilization (MB)") +
  theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) +
  theme(legend.position = "top") + labs(fill = "Statistic")
```

#### Host Performance Graphs

The purpose of the following graphs is to display the time series data for selected metrics.  These graphs allow for the visual assessment of systems performance.

##### Host CPU and Memory Percent Utilization


```{r CPUMemBar, fig.height= 4.2,reults = "asis", comment = "", echo = FALSE}
comp_n <- compInventory %>% arrange(hostName) %>% group_by(agentId) %>% nest()

agentIDs <- comp_n$agentId
Host = fixHostnames(map_chr(agentIDs, ~ subset(df,agentId == .x)$hostName[1]))
Data <-  map(agentIDs, ~ subset(df,agentId == .x))


for (i in 1:length(Host)) {
  
  ################################################################################## CPUUSAGPCT
  par(mfrow = c(2,1))
  hdr <- paste("Host: ", Host[i]," Metric: CpuUsagePct", sep = "")
  p <- ggplot(Data[[i]], aes(x = as.POSIXct(timestamp), y = CpuUsagePct)) + geom_line() + 
    ggtitle( label = hdr) + xlab("Date") + ylab("CPU Utilization Percent") +
    ylim(0, 100) +
    scale_x_datetime(breaks = date_breaks("days"), labels = date_format("%b-%d")) +
    theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))
  print(p)
  
  ############################################################################## MEMUSAGEPCT
  hdr <- paste("Host: ", Host[i]," Metric: MemUsagePct", sep = "")
  Data[[i]]$MemUsagePct <- (Data[[i]]$RAM.MB - Data[[i]]$freeRAM.MB) /  Data[[i]]$RAM.MB * 100
  p <- ggplot(Data[[i]], aes(x = as.POSIXct(timestamp), y = MemUsagePct)) + geom_line() + 
    ggtitle( label = hdr) + xlab("Date") + ylab("Memory Utilization Percent") + 
    ylim(0,100) + scale_x_datetime(breaks = date_breaks("days"), labels = date_format("%b-%d")) +
    theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1)) 
  print(p)  
  
}
```

#### Host Disk Bytes Read and Written


```{r DskBW, fig.height= 4.5,reults = "asis", comment = "", echo = FALSE}

for (i in 1:length(Host)) {
  
  ############################################################################## DISK READS + WRITES
  hdr <- paste("Host: ", Host[i]," Metric: DskBytes Written and Read", sep = "")
  dskDat <- Data[[i]] %>%
    select(c("timestamp","DiskBytesReadPS", "DiskBytesWrittenPS"))
  mDskDat <- melt(dskDat, id = "timestamp")
  p <- ggplot(mDskDat, aes(x = as.POSIXct(timestamp), y = value, color = variable)) + 
    geom_line() +
    ggtitle( label = hdr) + xlab("Date") + 
    ylab("Disk Read and Write Rates (Bytes per second)") +
    scale_fill_manual("Metric", values = c("red", "blue")) +
    scale_x_datetime(breaks = date_breaks("days"), labels = date_format("%b-%d")) +
    theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))  +
    theme(legend.position = "top") + labs(color = "Metric: ")
  
  print(p)
  
}
```

#### Host Network Reads and Writes per Second


```{r DskBR, fig.height= 6.0,reults = "asis", comment = "", echo = FALSE}

for (i in 1:length(Host)) {
  
  ###################################################################### NETWORK READS + WRITES
  hdr <- paste("Host: ", Host[i]," Metric: NetworkBytes Written and Read", sep = "")
  dskDat <- Data[[i]] %>%
    select(c("timestamp","NetworkBytesReadPS", "NetworkBytesWrittenPS"))
  mDskDat <- melt(dskDat, id = "timestamp")
  p <- ggplot(mDskDat, aes(x = as.POSIXct(timestamp), y = value, color = variable)) + geom_line() +
    ggtitle( label = hdr) + xlab("Date") + 
    ylab("Network Read and Write Rates (Bytes per second)") +
    scale_fill_manual("Metric", values = c("red", "blue"))  +
    scale_x_datetime(breaks = date_breaks("days"), labels = date_format("%b-%d")) +
    theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))  +
    theme(legend.position = "top") + labs(color = "Metric: ")
  
  print(p)
}
```



### Observations/Summary

#### Overall

As stated previously, all systems with the exception of **anand** are running within their capacities.  The reduction of memory and/or cores (vCPUs) might be appropriate for some hosts depending on projected workloads.  EM might consider consolidating several of its MySQL instances.

#### Host Anand Source Code Management 

Anand is used for SCM and CI.  Cloud providers have services to replace one or both of these services. 

#### Database as a Service (DBaaS)

EM might want to consider database as a service to reduce the number and size of servers required.  This will streamline host provisioning and eliminate the need to patch and maintain it own servers/operating systems and firmware updates.

AWS offers a DBaaS called Aurora.  Aurora currently supports versions of MySQL as well as PostGres.

**Run Date: **"`r format(Sys.time(), '%d %B %Y')`"

